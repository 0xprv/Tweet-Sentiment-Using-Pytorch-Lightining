{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('updated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "#data = data.sample(frac=1,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0.1</th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>541200</td>\n",
       "      <td>541200</td>\n",
       "      <td>0</td>\n",
       "      <td>['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>750</td>\n",
       "      <td>750</td>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>766711</td>\n",
       "      <td>766711</td>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'able', 'listen', 'yet', ' ', 'speaker',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>285055</td>\n",
       "      <td>285055</td>\n",
       "      <td>0</td>\n",
       "      <td>['remember', 'solve', 'relatively', 'big', 'eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>705995</td>\n",
       "      <td>705995</td>\n",
       "      <td>0</td>\n",
       "      <td>['eat', 'much', 'feel', 'sick']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>159217</td>\n",
       "      <td>159217</td>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'boyfriend', 'cut', 'hair', 'instead', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>298540</td>\n",
       "      <td>298540</td>\n",
       "      <td>0</td>\n",
       "      <td>['funny', 'home', 'video', '.......', 'wah', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>839945</td>\n",
       "      <td>839945</td>\n",
       "      <td>1</td>\n",
       "      <td>['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>732586</td>\n",
       "      <td>732586</td>\n",
       "      <td>0</td>\n",
       "      <td>['good', 'night', 'yesterday', 'wish', 'neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>429504</td>\n",
       "      <td>429504</td>\n",
       "      <td>0</td>\n",
       "      <td>['sunday', 'day', 'rest', 'many', 'another', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Unnamed: 0.1  Unnamed: 0  Target  \\\n",
       "0            541200      541200       0   \n",
       "1               750         750       0   \n",
       "2            766711      766711       0   \n",
       "3            285055      285055       0   \n",
       "4            705995      705995       0   \n",
       "...             ...         ...     ...   \n",
       "99995        159217      159217       0   \n",
       "99996        298540      298540       0   \n",
       "99997        839945      839945       1   \n",
       "99998        732586      732586       0   \n",
       "99999        429504      429504       0   \n",
       "\n",
       "                                                   Tweet  \n",
       "0      ['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...  \n",
       "1      ['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...  \n",
       "2      ['I', 'able', 'listen', 'yet', ' ', 'speaker',...  \n",
       "3      ['remember', 'solve', 'relatively', 'big', 'eq...  \n",
       "4                        ['eat', 'much', 'feel', 'sick']  \n",
       "...                                                  ...  \n",
       "99995  ['I', 'boyfriend', 'cut', 'hair', 'instead', '...  \n",
       "99996  ['funny', 'home', 'video', '.......', 'wah', '...  \n",
       "99997  ['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...  \n",
       "99998  ['good', 'night', 'yesterday', 'wish', 'neighb...  \n",
       "99999  ['sunday', 'day', 'rest', 'many', 'another', '...  \n",
       "\n",
       "[100000 rows x 4 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    50057\n",
       "0    49943\n",
       "Name: Target, dtype: int64"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].value_counts()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns=['Unnamed: 0','Unnamed: 0.1'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.columns = ['Target','Tweet']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'able', 'listen', 'yet', ' ', 'speaker',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['remember', 'solve', 'relatively', 'big', 'eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['eat', 'much', 'feel', 'sick']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'boyfriend', 'cut', 'hair', 'instead', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>['funny', 'home', 'video', '.......', 'wah', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>['good', 'night', 'yesterday', 'wish', 'neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>['sunday', 'day', 'rest', 'many', 'another', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target                                              Tweet\n",
       "0           0  ['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...\n",
       "1           0  ['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...\n",
       "2           0  ['I', 'able', 'listen', 'yet', ' ', 'speaker',...\n",
       "3           0  ['remember', 'solve', 'relatively', 'big', 'eq...\n",
       "4           0                    ['eat', 'much', 'feel', 'sick']\n",
       "...       ...                                                ...\n",
       "99995       0  ['I', 'boyfriend', 'cut', 'hair', 'instead', '...\n",
       "99996       0  ['funny', 'home', 'video', '.......', 'wah', '...\n",
       "99997       1  ['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...\n",
       "99998       0  ['good', 'night', 'yesterday', 'wish', 'neighb...\n",
       "99999       0  ['sunday', 'day', 'rest', 'many', 'another', '...\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "condition = data['Target'] == 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.loc[condition,'Target'] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['Target'].unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Text Preprocessing ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Target</th>\n",
       "      <th>Tweet</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'able', 'listen', 'yet', ' ', 'speaker',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>['remember', 'solve', 'relatively', 'big', 'eq...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>['eat', 'much', 'feel', 'sick']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99995</th>\n",
       "      <td>0</td>\n",
       "      <td>['I', 'boyfriend', 'cut', 'hair', 'instead', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99996</th>\n",
       "      <td>0</td>\n",
       "      <td>['funny', 'home', 'video', '.......', 'wah', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99997</th>\n",
       "      <td>1</td>\n",
       "      <td>['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99998</th>\n",
       "      <td>0</td>\n",
       "      <td>['good', 'night', 'yesterday', 'wish', 'neighb...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99999</th>\n",
       "      <td>0</td>\n",
       "      <td>['sunday', 'day', 'rest', 'many', 'another', '...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100000 rows × 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       Target                                              Tweet\n",
       "0           0  ['@nkluvr4eva', 'poor', 'little', 'dumple', ' ...\n",
       "1           0  ['I', 'bed', 'I', 'get', 'wake', 'hella', 'ear...\n",
       "2           0  ['I', 'able', 'listen', 'yet', ' ', 'speaker',...\n",
       "3           0  ['remember', 'solve', 'relatively', 'big', 'eq...\n",
       "4           0                    ['eat', 'much', 'feel', 'sick']\n",
       "...       ...                                                ...\n",
       "99995       0  ['I', 'boyfriend', 'cut', 'hair', 'instead', '...\n",
       "99996       0  ['funny', 'home', 'video', '.......', 'wah', '...\n",
       "99997       1  ['I', 'go', 'watch', 'tv', 'hopefully', 'tivo'...\n",
       "99998       0  ['good', 'night', 'yesterday', 'wish', 'neighb...\n",
       "99999       0  ['sunday', 'day', 'rest', 'many', 'another', '...\n",
       "\n",
       "[100000 rows x 2 columns]"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!python -m spacy download en_core_web_sm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_sm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/vishu/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 108,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [],
   "source": [
    "stopwo = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'!\"#$%&\\'()*+,-./:;<=>?@[\\\\]^_`{|}~'"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "string.punctuation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(data):\n",
    "    #lowercase\n",
    "    data = data.lower()\n",
    "    data = nlp(data)\n",
    "    data = [tk.lemma_ for tk in data]\n",
    "    final = []\n",
    "    for stp in data :\n",
    "        if stp not in stopwo and stp not in string.punctuation:\n",
    "            final.append(stp)\n",
    "\n",
    "    return final"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['hello', 'walking', 'go', 'name', 'abcd']\n"
     ]
    }
   ],
   "source": [
    "print(preprocess(\"Hello my walking went name is abcd ;+,./\"))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "prt = PorterStemmer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "def stemming(doc):\n",
    "    data = doc.lower()\n",
    "    data = nlp(doc)\n",
    "    return [prt.stem(dd.text) for dd in data]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['i', 'am', 'went']\n"
     ]
    }
   ],
   "source": [
    "print(stemming(\"I am went\"))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Word2Vec ##"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "data['Tweet'] = data['Tweet'].apply(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data.to_csv('updated_data.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {},
   "outputs": [],
   "source": [
    "total = len(data['Tweet'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "100000"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "total"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(total * 0.7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "70000"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = data.iloc[:train_split,-1]\n",
    "y_train = data.iloc[:train_split,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining_data = total - train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "30000"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test = data.iloc[train_split:train_split + 15000,-1]\n",
    "y_test = data.iloc[train_split:train_split + 15000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_val = data.iloc[train_split + 15000:train_split + 60000,-1]\n",
    "y_val = data.iloc[train_split + 15000:train_split + 60000,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "from gensim import corpora,similarities\n",
    "import ast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = [ast.literal_eval(vv) for vv in data['Tweet']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "list"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(vocab[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec.load(\"vocab.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = gensim.models.Word2Vec(window=10,min_count=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.build_vocab(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3325978, 4489625)"
      ]
     },
     "execution_count": 114,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.train(vocab,total_examples=model.corpus_count,epochs=model.epochs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.save(\"vocab.word2vec\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.wv['hate']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "artificial_vector = np.zeros(model.wv.vector_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,\n",
       "       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "artificial_vector"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorized_data = []\n",
    "index = []\n",
    "\n",
    "for _sent in vocab:\n",
    "    word_data = []\n",
    "    for word in _sent:\n",
    "        if word in model.wv.key_to_index:\n",
    "            word_data.append(model.wv[word])\n",
    "        else:\n",
    "            word_data.append(artificial_vector)\n",
    "    \n",
    "    vectorized_data.append(word_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishu/.local/lib/python3.10/site-packages/tqdm/auto.py:22: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from torch.nn.utils.rnn import pad_sequence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(5, 100)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.array(vectorized_data[8]).shape[-1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_4070/571836077.py:5: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at ../torch/csrc/utils/tensor_new.cpp:230.)\n",
      "  tensor.append(torch.Tensor(tweet))\n"
     ]
    }
   ],
   "source": [
    "tensor = []\n",
    "index = []\n",
    "for indx,tweet in enumerate(vectorized_data):\n",
    "    if np.array(tweet).ndim == 2 and np.array(tweet).shape[0] <= 20:\n",
    "        tensor.append(torch.Tensor(tweet))\n",
    "        index.append(indx)\n",
    "    else:\n",
    "        pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "99104"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(tensor)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "final_tensor = pad_sequence(tensor,batch_first=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([20, 100])"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_tensor[3].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import TensorDataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = data.iloc[index,0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "total_len = final_tensor.size(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_split = int(total_len * 0.8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "79283"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "remaining = total_len - train_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "19821"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "remaining"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = TensorDataset(final_tensor[0:train_split],torch.Tensor(target)[0:train_split])\n",
    "test_dataset = TensorDataset(final_tensor[train_split:train_split + 10000],torch.Tensor(target)[train_split:train_split + 10000])\n",
    "val_dataset = TensorDataset(final_tensor[train_split+10000:],torch.Tensor(target)[train_split + 10000:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_loader = DataLoader(train_dataset,batch_size=32)\n",
    "test_loader = DataLoader(test_dataset,batch_size=32)\n",
    "val_loader = DataLoader(val_dataset,batch_size=32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 185,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: lightning in /home/vishu/miniconda3/lib/python3.10/site-packages (2.0.9)\n",
      "Requirement already satisfied: Jinja2<5.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (3.1.2)\n",
      "Requirement already satisfied: PyYAML<8.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (6.0)\n",
      "Requirement already satisfied: arrow<3.0,>=1.2.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.2.3)\n",
      "Requirement already satisfied: backoff<4.0,>=2.2.1 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (2.2.1)\n",
      "Requirement already satisfied: beautifulsoup4<6.0,>=4.8.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (4.12.2)\n",
      "Requirement already satisfied: click<10.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (8.1.3)\n",
      "Requirement already satisfied: croniter<1.5.0,>=1.3.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.4.1)\n",
      "Requirement already satisfied: dateutils<2.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.6.12)\n",
      "Requirement already satisfied: deepdiff<8.0,>=5.7.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (6.5.0)\n",
      "Requirement already satisfied: fastapi<2.0,>=0.92.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.94.1)\n",
      "Requirement already satisfied: fsspec<2025.0,>=2022.5.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (2023.9.1)\n",
      "Requirement already satisfied: inquirer<5.0,>=2.10.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (3.1.3)\n",
      "Requirement already satisfied: lightning-cloud>=0.5.38 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.5.38)\n",
      "Requirement already satisfied: lightning-utilities<2.0,>=0.7.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.9.0)\n",
      "Requirement already satisfied: numpy<3.0,>=1.17.2 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (1.24.3)\n",
      "Requirement already satisfied: packaging in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (23.1)\n",
      "Requirement already satisfied: psutil<7.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (5.9.4)\n",
      "Requirement already satisfied: pydantic<2.2.0,>=1.7.4 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (1.10.5)\n",
      "Requirement already satisfied: python-multipart<2.0,>=0.0.5 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.0.6)\n",
      "Requirement already satisfied: requests<4.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (2.28.2)\n",
      "Requirement already satisfied: rich<15.0,>=12.3.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (13.3.3)\n",
      "Requirement already satisfied: starlette in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.26.1)\n",
      "Requirement already satisfied: starsessions<2.0,>=1.2.1 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.3.0)\n",
      "Requirement already satisfied: torch<4.0,>=1.11.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (1.13.1+cpu)\n",
      "Requirement already satisfied: torchmetrics<3.0,>=0.7.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.1.2)\n",
      "Requirement already satisfied: tqdm<6.0,>=4.57.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (4.64.1)\n",
      "Requirement already satisfied: traitlets<7.0,>=5.3.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (5.9.0)\n",
      "Requirement already satisfied: typing-extensions<6.0,>=4.0.0 in /home/vishu/.local/lib/python3.10/site-packages (from lightning) (4.5.0)\n",
      "Requirement already satisfied: urllib3<4.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.26.14)\n",
      "Requirement already satisfied: uvicorn<2.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (0.21.1)\n",
      "Requirement already satisfied: websocket-client<3.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (1.5.1)\n",
      "Requirement already satisfied: websockets<13.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (10.4)\n",
      "Requirement already satisfied: pytorch-lightning in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning) (2.0.9)\n",
      "Requirement already satisfied: python-dateutil>=2.7.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from arrow<3.0,>=1.2.0->lightning) (2.8.2)\n",
      "Requirement already satisfied: soupsieve>1.2 in /home/vishu/.local/lib/python3.10/site-packages (from beautifulsoup4<6.0,>=4.8.0->lightning) (2.4)\n",
      "Requirement already satisfied: pytz in /home/vishu/.local/lib/python3.10/site-packages (from dateutils<2.0->lightning) (2022.7.1)\n",
      "Requirement already satisfied: ordered-set<4.2.0,>=4.0.2 in /home/vishu/miniconda3/lib/python3.10/site-packages (from deepdiff<8.0,>=5.7.0->lightning) (4.1.0)\n",
      "Requirement already satisfied: aiohttp!=4.0.0a0,!=4.0.0a1 in /home/vishu/.local/lib/python3.10/site-packages (from fsspec<2025.0,>=2022.5.0->lightning) (3.8.4)\n",
      "Requirement already satisfied: blessed>=1.19.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.20.0)\n",
      "Requirement already satisfied: python-editor>=1.0.4 in /home/vishu/miniconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (1.0.4)\n",
      "Requirement already satisfied: readchar>=3.0.6 in /home/vishu/miniconda3/lib/python3.10/site-packages (from inquirer<5.0,>=2.10.0->lightning) (4.0.5)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in /home/vishu/.local/lib/python3.10/site-packages (from Jinja2<5.0->lightning) (2.1.3)\n",
      "Requirement already satisfied: pyjwt in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning-cloud>=0.5.38->lightning) (2.8.0)\n",
      "Requirement already satisfied: six in /home/vishu/miniconda3/lib/python3.10/site-packages (from lightning-cloud>=0.5.38->lightning) (1.16.0)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in /home/vishu/.local/lib/python3.10/site-packages (from requests<4.0->lightning) (3.0.1)\n",
      "Requirement already satisfied: idna<4,>=2.5 in /home/vishu/miniconda3/lib/python3.10/site-packages (from requests<4.0->lightning) (3.4)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in /home/vishu/miniconda3/lib/python3.10/site-packages (from requests<4.0->lightning) (2022.12.7)\n",
      "Requirement already satisfied: markdown-it-py<3.0.0,>=2.2.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.2.0)\n",
      "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /home/vishu/.local/lib/python3.10/site-packages (from rich<15.0,>=12.3.0->lightning) (2.14.0)\n",
      "Requirement already satisfied: anyio<5,>=3.4.0 in /home/vishu/.local/lib/python3.10/site-packages (from starlette->lightning) (3.6.2)\n",
      "Requirement already satisfied: itsdangerous<3.0.0,>=2.0.1 in /home/vishu/miniconda3/lib/python3.10/site-packages (from starsessions<2.0,>=1.2.1->lightning) (2.1.2)\n",
      "Requirement already satisfied: h11>=0.8 in /home/vishu/miniconda3/lib/python3.10/site-packages (from uvicorn<2.0->lightning) (0.14.0)\n",
      "Requirement already satisfied: attrs>=17.3.0 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (22.2.0)\n",
      "Requirement already satisfied: multidict<7.0,>=4.5 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (6.0.4)\n",
      "Requirement already satisfied: async-timeout<5.0,>=4.0.0a3 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (4.0.2)\n",
      "Requirement already satisfied: yarl<2.0,>=1.0 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.8.2)\n",
      "Requirement already satisfied: frozenlist>=1.1.1 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.3)\n",
      "Requirement already satisfied: aiosignal>=1.1.2 in /home/vishu/.local/lib/python3.10/site-packages (from aiohttp!=4.0.0a0,!=4.0.0a1->fsspec<2025.0,>=2022.5.0->lightning) (1.3.1)\n",
      "Requirement already satisfied: sniffio>=1.1 in /home/vishu/.local/lib/python3.10/site-packages (from anyio<5,>=3.4.0->starlette->lightning) (1.3.0)\n",
      "Requirement already satisfied: wcwidth>=0.1.4 in /home/vishu/.local/lib/python3.10/site-packages (from blessed>=1.19.0->inquirer<5.0,>=2.10.0->lightning) (0.2.6)\n",
      "Requirement already satisfied: mdurl~=0.1 in /home/vishu/miniconda3/lib/python3.10/site-packages (from markdown-it-py<3.0.0,>=2.2.0->rich<15.0,>=12.3.0->lightning) (0.1.2)\n",
      "Requirement already satisfied: setuptools>=41.0 in /home/vishu/miniconda3/lib/python3.10/site-packages (from readchar>=3.0.6->inquirer<5.0,>=2.10.0->lightning) (67.6.0)\n"
     ]
    }
   ],
   "source": [
    "!pip install lightning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pytorch_lightning as pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "INPUT_DIM = 100\n",
    "HIDDEN_DIM = 128\n",
    "BATCH = 32\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch\n",
    "import torch.nn.functional as f\n",
    "import torchmetrics\n",
    "from pytorch_lightning.callbacks import ModelCheckpoint,EarlyStopping"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 154,
   "metadata": {},
   "outputs": [],
   "source": [
    "class TWEET_SENTIMENT(pl.LightningModule):\n",
    "    def __init__(self,input_dim,hidden_dim):\n",
    "        super(TWEET_SENTIMENT,self).__init__()\n",
    "        self.input_dim = input_dim\n",
    "        self.hidden_dim = hidden_dim\n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        self.LSTM = nn.LSTM(input_size = input_dim,hidden_size = hidden_dim,batch_first = True)\n",
    "        self.h0 = torch.zeros(size = (1,32,self.hidden_dim))\n",
    "        self.c0 = torch.zeros(size = (1,32,self.hidden_dim))\n",
    "        self.accuracy = torchmetrics.F1Score(task=\"multiclass\",num_classes=2)\n",
    "        self.fc1 = nn.Linear(128,64)\n",
    "        self.fc2 = nn.Linear(64,2)\n",
    "\n",
    "    def forward(self,x):\n",
    "        #x -> 32,38,100\n",
    "        h,c = self.LSTM(x,(self.h0,self.c0))\n",
    "        #h-> 32,38,128\n",
    "        h = h[:,-1,:] # 32,128\n",
    "        h = self.fc1(h)\n",
    "        h = f.relu(h)\n",
    "        h = self.fc2(h)\n",
    "        h = f.softmax(h,dim=-1)\n",
    "        return h\n",
    "\n",
    "    def training_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        if x.size(0) == 32:\n",
    "            y = y.long()\n",
    "            pred = self(x)\n",
    "            loss = self.criterion(pred,y)\n",
    "            accuracy = self.accuracy(pred,y)\n",
    "            self.log_dict({'Train loss':loss , 'Accuracy':accuracy},on_epoch=True,prog_bar=True)\n",
    "            return {'loss':loss}\n",
    "        return None\n",
    "    \n",
    "    def validation_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        if x.size(0) == 32:\n",
    "            y = y.long()\n",
    "            pred = self(x)\n",
    "            accuracy = self.accuracy(pred,y)\n",
    "            loss = self.criterion(pred,y)\n",
    "            self.log_dict({'Validation loss':loss,'Accuracy':accuracy},on_epoch=True,prog_bar=True)\n",
    "            return loss\n",
    "        return None\n",
    "    \n",
    "    def test_step(self,batch,batch_idx):\n",
    "        x,y = batch\n",
    "        if x.size(0) == 32:\n",
    "            y = y.long()\n",
    "            pred = self(x)\n",
    "            accuracy = self.accuracy(pred,y)\n",
    "            loss = self.criterion(pred,y)\n",
    "            self.log_dict({'Test loss':loss,'Accuracy':accuracy},on_epoch=True,prog_bar=True)\n",
    "            return loss\n",
    "        return None\n",
    "    \n",
    "    def configure_optimizers(self):\n",
    "        return torch.optim.Adam(self.parameters(),lr=0.001)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_callback = ModelCheckpoint(\n",
    "    monitor='val_loss',\n",
    "    dirpath='checkpoints/',\n",
    "    filename='model-{epoch:02d}-{val_loss:.2f}',\n",
    "    save_top_k=1, \n",
    "    mode='min',\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "GPU available: False, used: False\n",
      "TPU available: False, using: 0 TPU cores\n",
      "IPU available: False, using: 0 IPUs\n",
      "HPU available: False, using: 0 HPUs\n"
     ]
    }
   ],
   "source": [
    "trainer = pl.Trainer(accelerator='auto',\n",
    "                     min_epochs=1,max_epochs=10,\n",
    "                     callbacks=[EarlyStopping(monitor='val_loss',patience=3),checkpoint_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 156,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_model = TWEET_SENTIMENT(INPUT_DIM,128)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_model = torch.load('TWEET_MODEL.pt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "TWEET_SENTIMENT(\n",
       "  (criterion): CrossEntropyLoss()\n",
       "  (LSTM): LSTM(100, 128, batch_first=True)\n",
       "  (accuracy): MulticlassF1Score()\n",
       "  (fc1): Linear(in_features=128, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=2, bias=True)\n",
       ")"
      ]
     },
     "execution_count": 167,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet_model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 6:  12%|█▏        | 291/2478 [00:12<01:33, 23.31it/s, v_num=6, Train loss_step=0.403, Accuracy_step=0.812, Validation loss=0.510, Accuracy=0.748, Train loss_epoch=0.478, Accuracy_epoch=0.764] "
     ]
    }
   ],
   "source": [
    "trainer.fit(tweet_model,train_loader,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.save(tweet_model,\"TWEET_MODEL.pt\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishu/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, test_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0:   2%|▏         | 5/313 [00:00<00:31,  9.84it/s]"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Testing DataLoader 0: 100%|██████████| 313/313 [00:11<00:00, 26.56it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">        Test metric        </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7517027258872986     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Test loss         </span>│<span style=\"color: #800080; text-decoration-color: #800080\">     0.562911331653595     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m       Test metric       \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7517027258872986    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Test loss        \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m    0.562911331653595    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'Test loss': 0.562911331653595, 'Accuracy': 0.7517027258872986}]"
      ]
     },
     "execution_count": 158,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.test(tweet_model,test_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/vishu/miniconda3/lib/python3.10/site-packages/pytorch_lightning/trainer/connectors/data_connector.py:442: PossibleUserWarning: The dataloader, val_dataloader, does not have many workers which may be a bottleneck. Consider increasing the value of the `num_workers` argument` (try 8 which is the number of cpus on this machine) in the `DataLoader` init to improve performance.\n",
      "  rank_zero_warn(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Validation DataLoader 0: 100%|██████████| 307/307 [00:09<00:00, 32.20it/s]\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\">      Validate metric      </span>┃<span style=\"font-weight: bold\">       DataLoader 0        </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">         Accuracy          </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.7528594732284546     </span>│\n",
       "│<span style=\"color: #008080; text-decoration-color: #008080\">      Validation loss      </span>│<span style=\"color: #800080; text-decoration-color: #800080\">    0.4996325373649597     </span>│\n",
       "└───────────────────────────┴───────────────────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1m     Validate metric     \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      DataLoader 0       \u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━━━━┩\n",
       "│\u001b[36m \u001b[0m\u001b[36m        Accuracy         \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.7528594732284546    \u001b[0m\u001b[35m \u001b[0m│\n",
       "│\u001b[36m \u001b[0m\u001b[36m     Validation loss     \u001b[0m\u001b[36m \u001b[0m│\u001b[35m \u001b[0m\u001b[35m   0.4996325373649597    \u001b[0m\u001b[35m \u001b[0m│\n",
       "└───────────────────────────┴───────────────────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "[{'Validation loss': 0.4996325373649597, 'Accuracy': 0.7528594732284546}]"
      ]
     },
     "execution_count": 124,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trainer.validate(tweet_model,val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 175,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = \"My dog is missing from 9 days\"\n",
    "tweet = preprocess(tweet)\n",
    "tweet = [model.wv[t] for t in tweet]\n",
    "tweet = torch.Tensor(tweet) #5,100\n",
    "tweet = tweet.unsqueeze(0) #1,5,100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 176,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet = tweet.repeat(32,1,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 177,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([32, 4, 100])"
      ]
     },
     "execution_count": 177,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tweet.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 178,
   "metadata": {},
   "outputs": [],
   "source": [
    "tweet_model.eval()\n",
    "with torch.no_grad():\n",
    "    predi = tweet_model(tweet)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 179,
   "metadata": {},
   "outputs": [],
   "source": [
    "result = torch.argmax(predi[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 180,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Negative Sentiment\n"
     ]
    }
   ],
   "source": [
    "if result.item() == 1:\n",
    "    print(\"Positive Sentiment\")\n",
    "else:\n",
    "    print(\"Negative Sentiment\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
